<h1 align="center">RL基础知识 & GRPO公式推导</h1>

# RL基础概念：S、A、R、π

## 状态 s
## 动作 a
## 奖励 r
## 策略 π
## 确定性环境 & 概率环境
## 在LLM中的对应

# 衍生概念：G、V、A、Q

## 回报G
## 价值V
## 优势A
## Q函数

## 贝尔曼方程 & R/V/Q/A之间的关系
### 标准意义下（概率环境）
### 确定性环境中的简化形式

## 在LLM中的对应

# 蒙特卡洛：估计V/A/Q
（时序差分最终演化为PPO，蒙特卡洛最终演化为GRPO，理解GRPO并不需要理解时序差分）

## 在LLM中的对应

# GRPO：简化场景中的蒙特卡洛
GPRO = 确定性环境+单步决策下的蒙特卡洛
